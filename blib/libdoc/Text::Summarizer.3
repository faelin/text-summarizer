.\" Automatically generated by Pod::Man 4.07 (Pod::Simple 3.32)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
.    ds C`
.    ds C'
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is >0, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.SS), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.\"
.\" Avoid warning from groff about undefined register 'F'.
.de IX
..
.if !\nF .nr F 0
.if \nF>0 \{\
.    de IX
.    tm Index:\\$1\t\\n%\t"\\$2"
..
.    if !\nF==2 \{\
.        nr % 0
.        nr F 2
.    \}
.\}
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "Text::Summarizer 3"
.TH Text::Summarizer 3 "2018-02-20" "perl v5.24.0" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
Text::Summarizer \- Summarize Bodies of Text
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.Vb 1
\&        use Text::Summarizer;
\&        
\&        my $summarizer = Text::Summarizer\->new( print_scanner => 1, print_summary => 1 );
\&        
\&                # to summarize a string
\&        $new_words = $summarizer\->scan_text( \*(Aqthis is a sample text\*(Aq );
\&        $summary   = $summarizer\->summ_text( \*(Aqthis is a sample text\*(Aq );
\&            # or to summarize an entire file
\&        $new_words = $summarizer\->scan_file("some/file.txt");
\&        $summary   = $summarizer\->summ_file("some/file.txt");
\&                # or to summarize in bulk
\&        @new_words = $summarizer\->scan_each("/directory/glob/*");
\&        @summaries = $summarizer\->summ_each("/directory/glob/*");
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
This module allows you to summarize bodies of text into a scored hash of  \fIsentences\fR,  \fIphrase-fragments\fR, and  \fIindividual words\fR from the provided text. These scores reflect the weight (or precedence) of the relative text-fragments, i.e. how well they summarize or reflect the overall nature of the text. All of the sentences and phrase-fragments are drawn from within the existing text, and are \s-1NOT\s0 proceedurally generated.
.SH "ATTRIBUTES"
.IX Header "ATTRIBUTES"
\&\fB The following constructor attributes are available to the user, and can be accessed/modified at any time via \f(CB\*(C`$summarizer\->_set_[attribute]\*(C'\fB \fR:
.ie n .IP """articles_path""   X [directory]" 8
.el .IP "\f(CWarticles_path\fR   X [directory]" 8
.IX Item "articles_path X [directory]"
folder containing some text-files you wish to summarize
.ie n .IP """permanent_path""  X [filepath]" 8
.el .IP "\f(CWpermanent_path\fR  X [filepath]" 8
.IX Item "permanent_path X [filepath]"
file containing a base set of universal stopwords (defaults to English stopwords)
.ie n .IP """stopwords_path""  X [filepath]" 8
.el .IP "\f(CWstopwords_path\fR  X [filepath]" 8
.IX Item "stopwords_path X [filepath]"
file containing a list of new stopwords identified by the \f(CW\*(C`scan\*(C'\fR function
.ie n .IP """store_scanner""   X [boolean]" 8
.el .IP "\f(CWstore_scanner\fR   X [boolean]" 8
.IX Item "store_scanner X [boolean]"
flag for storing new stopwords in the file indicated by \f(CW\*(C`stopwords_path\*(C'\fR
.ie n .IP """print_scanner""   X [boolean]" 8
.el .IP "\f(CWprint_scanner\fR   X [boolean]" 8
.IX Item "print_scanner X [boolean]"
flag that enables visual graphing of scanner activity (prints to \f(CW\*(C`STDOUT\*(C'\fR)
.ie n .IP """print_summary""   X [boolean]" 8
.el .IP "\f(CWprint_summary\fR   X [boolean]" 8
.IX Item "print_summary X [boolean]"
flag that enables visual charting of summary activity (prints to \f(CW\*(C`STDOUT\*(C'\fR)
.ie n .IP """return_count""    X [int]" 8
.el .IP "\f(CWreturn_count\fR    X [int]" 8
.IX Item "return_count X [int]"
number of items to list when printing summary list
.ie n .IP """phrase_thresh""   X [int]" 8
.el .IP "\f(CWphrase_thresh\fR   X [int]" 8
.IX Item "phrase_thresh X [int]"
minimum number of word tokens allowed in a phrase
.ie n .IP """phrase_radius""   X [int]" 8
.el .IP "\f(CWphrase_radius\fR   X [int]" 8
.IX Item "phrase_radius X [int]"
distance iterated backward and forward from a given word when establishing a phrase (i.e. maximum length of phrase divided by 2)
.ie n .IP """freq_constant""   X [float]" 8
.el .IP "\f(CWfreq_constant\fR   X [float]" 8
.IX Item "freq_constant X [float]"
mathematical constant for establishing minimum threshold of occurence for frequently occuring words (defaults to \f(CW0.004\fR)
.PP
\&\fB These attributes are read-only, and can be accessed via \f(CB\*(C`$summarizer\->[attribute]\*(C'\fB \fR:
.ie n .IP """full_text"" X [string]" 8
.el .IP "\f(CWfull_text\fR X [string]" 8
.IX Item "full_text X [string]"
all the lines of the provided text, joined together
.ie n .IP """sentences"" X [array\-ref]" 8
.el .IP "\f(CWsentences\fR X [array\-ref]" 8
.IX Item "sentences X [array-ref]"
list of each sentence found in the provided text
.ie n .IP """sen_words"" X [array\-ref]" 8
.el .IP "\f(CWsen_words\fR X [array\-ref]" 8
.IX Item "sen_words X [array-ref]"
for each sentence, contains an array of each word in order
.ie n .IP """word_list"" X [array\-ref]" 8
.el .IP "\f(CWword_list\fR X [array\-ref]" 8
.IX Item "word_list X [array-ref]"
each individual word of the entire text, in order (token stream)
.ie n .IP """freq_hash"" X [hash\-ref]" 8
.el .IP "\f(CWfreq_hash\fR X [hash\-ref]" 8
.IX Item "freq_hash X [hash-ref]"
all words that occur more than a specified threshold, paired with their frequency of occurence
.ie n .IP """clst_hash"" X [hash\-ref]" 8
.el .IP "\f(CWclst_hash\fR X [hash\-ref]" 8
.IX Item "clst_hash X [hash-ref]"
for each word in the text, specifies the position of each occurence of the word, both relative to the sentence it occurs in and absolute within the text
.ie n .IP """phrs_hash"" X [hash\-ref]" 8
.el .IP "\f(CWphrs_hash\fR X [hash\-ref]" 8
.IX Item "phrs_hash X [hash-ref]"
for each word in the text, contains a phrase of radius \fIr\fR centered around the given word, and references the sentence from which the phrase was gathered
.ie n .IP """sigma_hash"" X [hash\-ref]" 8
.el .IP "\f(CWsigma_hash\fR X [hash\-ref]" 8
.IX Item "sigma_hash X [hash-ref]"
gives the population standard deviation of the clustering of each word in the text
.ie n .IP """inter_hash"" X [hash\-ref]" 8
.el .IP "\f(CWinter_hash\fR X [hash\-ref]" 8
.IX Item "inter_hash X [hash-ref]"
list of each chosen phrase-fragment-scrap, paired with its score
.ie n .IP """score_hash"" X [hash\-ref]" 8
.el .IP "\f(CWscore_hash\fR X [hash\-ref]" 8
.IX Item "score_hash X [hash-ref]"
list of each word in the text, paired with its score
.ie n .IP """phrs_list""  X [hash\-ref]" 8
.el .IP "\f(CWphrs_list\fR  X [hash\-ref]" 8
.IX Item "phrs_list X [hash-ref]"
list of complete sentences that each scrap was drawn from, paired with its score
.ie n .IP """frag_list""  X [array\-ref]" 8
.el .IP "\f(CWfrag_list\fR  X [array\-ref]" 8
.IX Item "frag_list X [array-ref]"
for each chosen scrap, contains a hash of: the pivot word of the scrap; the sentence containing the scrap; the number of occurences of each word in the sentence; an ordered list of the words in the phrase from which the scrap was derived
.ie n .IP """file_name"" X [string]" 8
.el .IP "\f(CWfile_name\fR X [string]" 8
.IX Item "file_name X [string]"
the filename of the current text-source (if text was extracted from a file)
.ie n .IP """text_hint"" X [string]" 8
.el .IP "\f(CWtext_hint\fR X [string]" 8
.IX Item "text_hint X [string]"
brief snippet of text containing the first 50 and the final 30 characters of the current text
.ie n .IP """summary"" X [hash\-ref]" 8
.el .IP "\f(CWsummary\fR X [hash\-ref]" 8
.IX Item "summary X [hash-ref]"
scored lists of each summary sentence, each chosen scrap, and each frequently-occuring word
.ie n .IP """stopwords"" \- [hash\-ref]" 8
.el .IP "\f(CWstopwords\fR \- [hash\-ref]" 8
.IX Item "stopwords - [hash-ref]"
list of all stopwords, both permanent and proceedural
.ie n .IP """watchlist"" \- [hash\-ref]" 8
.el .IP "\f(CWwatchlist\fR \- [hash\-ref]" 8
.IX Item "watchlist - [hash-ref]"
list of proceedurally generated stopwords, derived by the `scan` function
.SH "FUNCTIONS"
.IX Header "FUNCTIONS"
.ie n .SS """scan"""
.el .SS "\f(CWscan\fP"
.IX Subsection "scan"
Scan is a utility that allows the Text::Summarizer to parse through a body of text to find words that occur with unusually high frequency. These words are then stored as new stopwords via the provided \f(CW\*(C`stopwords_path\*(C'\fR. Additionally, calling any of the three \f(CW\*(C`scan_[...]\*(C'\fR subroutines will return a reference (or array of references) to an unordered list containing the new stopwords.
.PP
.Vb 3
\&        $new_words     = $summarizer\->scan_text( \*(Aqthis is a sample text\*(Aq );
\&        $new_words     = $summarizer\->scan_file( \*(Aqsome/file/path.txt\*(Aq );
\&        @arr_new_words = $summarizer\->scan_each( \*(Aqsome/directory/*\*(Aq );
.Ve
.ie n .SS """summarize"""
.el .SS "\f(CWsummarize\fP"
.IX Subsection "summarize"
Summarizing is, not surprisingly, the heart of the Text::Summarizer. Summarizing a body of text provides three distinct categories of information drawn from the existing text and ordered by relevance to the summary: \fIfull sentences\fR, \fIphrase-fragments / context-free token streams\fR, and a list of \fIfrequently occuring words\fR.
.PP
There are three provided functions for summarizing text documents.
.PP
.Vb 7
\&        $summary   = $summarizer\->summarize_text( \*(Aqthis is a sample text\*(Aq );
\&        $summary   = $summarizer\->summarize_file( \*(Aqsome/file/path.txt\*(Aq );
\&        @summaries = $summarizer\->summarize_each( \*(Aqsome/directory/*\*(Aq );
\&                # or their short forms
\&        $summary   = $summarizer\->summ_text(\*(Aq...\*(Aq);
\&        $summary   = $summarizer\->summ_file(\*(Aq...\*(Aq);
\&        @sumamries = $summarizer\->summ_each(\*(Aq...\*(Aq);
.Ve
.PP
\&\f(CW\*(C`summarize_text\*(C'\fR and \f(CW\*(C`summarize_file\*(C'\fR each return a summary hash-ref containing three array-refs, while \f(CW\*(C`summarize_each\*(C'\fR returns a list of these hash-refs. These summary hashes take the following form:
.IP "\(bu" 8
\&\f(CW\*(C`sentences\*(C'\fR => a list of full sentences from the given text, with composite scores of the words contained therein
.IP "\(bu" 8
\&\f(CW\*(C`fragments\*(C'\fR => a list of phrase fragments from the given text, scored similarly to sentences
.IP "\(bu" 8
\&\f(CW\*(C`words\*(C'\fR     => a list of all words in the text, scored by a three-factor system consisting of  \fIfrequency of appearance\fR,  \fIpopulation standard deviation\fR, and  \fIuse in important phrase fragments\fR.
.PP
\fIAbout Fragments\fR
.IX Subsection "About Fragments"
.PP
Phrase fragments are in actuality short \*(L"scraps\*(R" of text (usually only two or three words) that are derived from the text via the following process:
.IP "1." 8
the entirety of the text is tokenized and scored into a \f(CW\*(C`frequency\*(C'\fR table, with a high-pass threshold of frequencies above \f(CW\*(C`# of tokens * user\-defined scaling factor\*(C'\fR
.IP "2." 8
each sentence is tokenized and stored in an array
.IP "3." 8
for each word within the \f(CW\*(C`frequency\*(C'\fR table, a table of phrase-fragments is derived by finding each occurance of said word and tracking forward and backward by a user-defined \*(L"radius\*(R" of tokens (defaults to \f(CW\*(C`radius\ =\ 5\*(C'\fR, does not include the central key-word) X each phrase-fragment is thus compiled of (by default) an 11\-token string
.IP "4." 8
all fragments for a given key-word are then compared to each other, and each word is deleted if it appears only once amongst all of the fragments (leaving only \f(CW\*(C`\f(CIA\f(CW X \f(CIB\f(CW X ... X \f(CIS\f(CW\*(C'\fR where \fIA\fR, \fIB\fR, ..., \fIS\fR are the phrase-fragments)
.IP "5." 8
what remains of each fragment is a list of \*(L"scraps\*(R" X strings of consecutive tokens X from which the longest scrap is chosen as a representation of the given phrase-fragment
.IP "6." 8
when a shorter fragment-scrap (\f(CW\*(C`\f(CIA\f(CW\*(C'\fR) is included in the text of a longer scrap (\f(CW\*(C`\f(CIB\f(CW\*(C'\fR) such that \f(CW\*(C`\f(CIA\f(CW X \f(CIB\f(CW\*(C'\fR, the shorter is deleted and its score is added to that of the longer
.IP "7." 8
when multiple fragments are equivalent (i.e. they consist of the same list of tokens when stopwords are excluded), they are condensed into a single scrap in the form of \f(CW"(some|word|tokens)"\fR such that the fragment now represents the tokens of the scrap (excluding stopwords) regardless of order (refered to as a \*(L"context-free token stream\*(R")
.SH "SUPPORT"
.IX Header "SUPPORT"
Bugs should always be submitted via the project hosting bug tracker
.PP
<https://github.com/faelin/text\-summarizer/issues>
.PP
For other issues, contact the maintainer.
.SH "AUTHOR"
.IX Header "AUTHOR"
Faelin Landy <faelin.landy@gmail.com> (current maintainer)
.SH "CONTRIBUTORS"
.IX Header "CONTRIBUTORS"
* Michael McClennen <michaelm@umich.edu>
.SH "COPYRIGHT AND LICENSE"
.IX Header "COPYRIGHT AND LICENSE"
Copyright (c) 2018 by the \s-1AUTHOR\s0 as listed above
.PP
This program is free software: you can redistribute it and/or modify it under the terms of the \s-1GNU\s0 Lesser General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.
.PP
This program is distributed in the hope that it will be useful, but \s-1WITHOUT ANY WARRANTY\s0; without even the implied warranty of \s-1MERCHANTABILITY\s0 or \s-1FITNESS FOR A PARTICULAR PURPOSE.\s0 See the \s-1GNU\s0 Lesser General Public License for more details.
